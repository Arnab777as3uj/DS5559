{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5ChmLicLhzI"
   },
   "source": [
    "# Synopsis\n",
    "\n",
    "Here we create a TFIDF matrix from our corpus of novels, and then save a reduced version of this for use in HCA and PCA models. We choose to limit our vocabulary to 1000 top words, based on high-frequency non-stopwords.\n",
    "\n",
    "We begin by extracting a bag-of-words from the token table. Note that we could have chosen a different set of \"bags,\" e.g. paragraphs or an arbitrary chunk of n tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWADUMoUp8_p"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcwLF3YyqmVZ"
   },
   "outputs": [],
   "source": [
    "db_name = 'novels.db'\n",
    "\n",
    "OHCO = ['genre', 'author', 'book', 'chapter', 'para_num', 'sent_num', 'token_num']\n",
    "GENRS = OHCO[:1]\n",
    "AUTHS = OHCO[:2]\n",
    "BOOKS = OHCO[:3]\n",
    "CHAPS = OHCO[:4]\n",
    "PARAS = OHCO[:5]\n",
    "SENTS = OHCO[:6]\n",
    "\n",
    "BAG = CHAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLdKbNbMLmI1"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbadDvzWW0Sw"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbadDvzWW0Sw"
   },
   "source": [
    "# Pragmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbadDvzWW0Sw"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYW-zAG1LpTP",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hefj5mkCLo0D"
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_name) as db:\n",
    "    tokens = pd.read_sql('SELECT * FROM token', db, index_col=OHCO)\n",
    "    vocab = pd.read_sql('SELECT * FROM vocab', db, index_col='term_id')\n",
    "    docs =  pd.read_sql('SELECT * FROM doc', db, index_col=CHAPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WoDnI5rmg6h",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Create DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WoDnI5rmg6h"
   },
   "source": [
    "### Create word mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJQvJsdwTIra"
   },
   "outputs": [],
   "source": [
    "WORDS = (tokens.punc == 0) & (tokens.num == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9-E_3-WmjzR"
   },
   "source": [
    "### Extrct BOW from tokens\n",
    "\n",
    "To extract a bag-of-words model from our tokens table, we apply a simple `groupby()` operation. Note that we can drop in our hyperparameters easily -- CHAPS and 'term_id' and be replaced. We can easily write a function to simplify this process and make it more configurable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ax8ePBkk4qP"
   },
   "outputs": [],
   "source": [
    "BOW = tokens[WORDS].groupby(BAG + ['term_id'])['term_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tiOTaBLCmmKP"
   },
   "source": [
    "### Convert BOW to DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4tYnLT5lu0J"
   },
   "outputs": [],
   "source": [
    "DTM = BOW.unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foZvi_brzyNR"
   },
   "source": [
    "### Create Bags table\n",
    "\n",
    "The bags table stores the OHCO content for each doc, since we remove this from the DTM. We can add some stats to this table if we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TgoLS_xIu_a"
   },
   "outputs": [],
   "source": [
    "bags = pd.DataFrame(index = DTM.index)\n",
    "# bags['term_count'] = DTM.sum(1)\n",
    "# bags['tf'] = bags.term_count / bags.term_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TgoLS_xIu_a"
   },
   "outputs": [],
   "source": [
    "DTM = DTM.reset_index(drop=True)\n",
    "DTM.index.name = 'bag_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbYmZJUO_oKx",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Compute Term Frequencies and Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IBFLaQODVPH"
   },
   "source": [
    "### Compute TF\n",
    "\n",
    "Note that TF is just the term count. It is often normalized in the computing the value, but it is defined as the count in the context of information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "source": [
    "### Compute IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "outputs": [],
   "source": [
    "N_docs = DTM.shape[0]\n",
    "vocab['df'] = DTM[DTM > 0].count()\n",
    "vocab['idf'] = np.log10(N_docs / vocab.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "source": [
    "### Test: View most frequent non-stops by IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>port_stem</th>\n",
       "      <th>stop</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14675</th>\n",
       "      <td>manfred</td>\n",
       "      <td>277</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>manfr</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131</th>\n",
       "      <td>scrooge</td>\n",
       "      <td>314</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>scroog</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17654</th>\n",
       "      <td>philip</td>\n",
       "      <td>230</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>philip</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.550907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>antonia</td>\n",
       "      <td>246</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>antonia</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.550907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>edmund</td>\n",
       "      <td>358</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>edmund</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.505150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14886</th>\n",
       "      <td>matilda</td>\n",
       "      <td>326</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>matilda</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.391207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12623</th>\n",
       "      <td>inglethorp</td>\n",
       "      <td>263</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>inglethorp</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.391207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18037</th>\n",
       "      <td>poirot</td>\n",
       "      <td>386</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>poirot</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.391207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>agnes</td>\n",
       "      <td>247</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>agn</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.249877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td>helsing</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>hels</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.226396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14424</th>\n",
       "      <td>ludovico</td>\n",
       "      <td>249</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>ludovico</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.182931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>godfrey</td>\n",
       "      <td>227</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>godfrey</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.162727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>baron</td>\n",
       "      <td>285</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>baron</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.162727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13395</th>\n",
       "      <td>julius</td>\n",
       "      <td>304</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>juliu</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1.143422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26017</th>\n",
       "      <td>van</td>\n",
       "      <td>327</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>van</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1.124939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21388</th>\n",
       "      <td>sergeant</td>\n",
       "      <td>489</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>sergeant</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.090177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>cuff</td>\n",
       "      <td>235</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>cuff</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.090177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25026</th>\n",
       "      <td>tuppence</td>\n",
       "      <td>585</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>tuppenc</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.090177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>isabella</td>\n",
       "      <td>311</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>isabella</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.073786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24529</th>\n",
       "      <td>tommy</td>\n",
       "      <td>544</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>tommi</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.073786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str    n         p   port_stem  stop  df       idf\n",
       "term_id                                                           \n",
       "14675       manfred  277  0.000185       manfr     0   5  1.806180\n",
       "21131       scrooge  314  0.000209      scroog     0   5  1.806180\n",
       "17654        philip  230  0.000153      philip     0   9  1.550907\n",
       "999         antonia  246  0.000164     antonia     0   9  1.550907\n",
       "7759         edmund  358  0.000239      edmund     0  10  1.505150\n",
       "14886       matilda  326  0.000217     matilda     0  13  1.391207\n",
       "12623    inglethorp  263  0.000175  inglethorp     0  13  1.391207\n",
       "18037        poirot  386  0.000257      poirot     0  13  1.391207\n",
       "540           agnes  247  0.000165         agn     0  18  1.249877\n",
       "11396       helsing  300  0.000200        hels     0  19  1.226396\n",
       "14424      ludovico  249  0.000166    ludovico     0  21  1.182931\n",
       "10573       godfrey  227  0.000151     godfrey     0  22  1.162727\n",
       "1882          baron  285  0.000190       baron     0  22  1.162727\n",
       "13395        julius  304  0.000203       juliu     0  23  1.143422\n",
       "26017           van  327  0.000218         van     0  24  1.124939\n",
       "21388      sergeant  489  0.000326    sergeant     0  26  1.090177\n",
       "5732           cuff  235  0.000157        cuff     0  26  1.090177\n",
       "25026      tuppence  585  0.000390     tuppenc     0  26  1.090177\n",
       "13136      isabella  311  0.000207    isabella     0  27  1.073786\n",
       "24529         tommy  544  0.000363       tommi     0  27  1.073786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab.stop==0].sort_values('n', ascending=False).head(500)\\\n",
    "    .sort_values('idf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6pFEbf5NAbvl"
   },
   "source": [
    "### Compute TFIDF\n",
    "\n",
    "See [Simone Teufel's lectures](https://www.cl.cam.ac.uk/teaching/1415/InfoRtrv/lecture4.pdf)\n",
    "\n",
    "```\n",
    "TF: term count\n",
    "N: number of docs\n",
    "DF: number of docs with term\n",
    "log = log10\n",
    "\n",
    "(1 + log(TF)) * log( N / DF)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "outputs": [],
   "source": [
    "TFIDF = DTM * vocab['idf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "source": [
    "### Test: Stopwords Detected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3vd2eNs-fif"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>port_stem</th>\n",
       "      <th>stop</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>28533</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>and</td>\n",
       "      <td>44991</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>as</td>\n",
       "      <td>11252</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>as</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>be</td>\n",
       "      <td>8787</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>be</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>but</td>\n",
       "      <td>9528</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>but</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>by</td>\n",
       "      <td>6923</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>by</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>for</td>\n",
       "      <td>11150</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>from</td>\n",
       "      <td>6780</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>from</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>had</td>\n",
       "      <td>12858</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>had</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>have</td>\n",
       "      <td>9099</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12267</th>\n",
       "      <td>in</td>\n",
       "      <td>23501</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13157</th>\n",
       "      <td>it</td>\n",
       "      <td>18445</td>\n",
       "      <td>0.012293</td>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16135</th>\n",
       "      <td>no</td>\n",
       "      <td>5200</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>not</td>\n",
       "      <td>10069</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16459</th>\n",
       "      <td>of</td>\n",
       "      <td>42638</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16539</th>\n",
       "      <td>on</td>\n",
       "      <td>8689</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24121</th>\n",
       "      <td>that</td>\n",
       "      <td>21120</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24127</th>\n",
       "      <td>the</td>\n",
       "      <td>85329</td>\n",
       "      <td>0.056870</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24229</th>\n",
       "      <td>this</td>\n",
       "      <td>7512</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>thi</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24470</th>\n",
       "      <td>to</td>\n",
       "      <td>45176</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n         p port_stem  stop   df  idf\n",
       "term_id                                                    \n",
       "0              a  28533  0.019017         a     1  320  0.0\n",
       "862          and  44991  0.029986       and     1  320  0.0\n",
       "1328          as  11252  0.007499        as     1  320  0.0\n",
       "1987          be   8787  0.005856        be     1  320  0.0\n",
       "3209         but   9528  0.006350       but     1  320  0.0\n",
       "3237          by   6923  0.004614        by     1  320  0.0\n",
       "9681         for  11150  0.007431       for     1  320  0.0\n",
       "10024       from   6780  0.004519      from     1  320  0.0\n",
       "11006        had  12858  0.008570       had     1  320  0.0\n",
       "11241       have   9099  0.006064      have     1  320  0.0\n",
       "12267         in  23501  0.015663        in     1  320  0.0\n",
       "13157         it  18445  0.012293        it     1  320  0.0\n",
       "16135         no   5200  0.003466        no     1  320  0.0\n",
       "16213        not  10069  0.006711       not     1  320  0.0\n",
       "16459         of  42638  0.028417        of     1  320  0.0\n",
       "16539         on   8689  0.005791        on     1  320  0.0\n",
       "24121       that  21120  0.014076      that     1  320  0.0\n",
       "24127        the  85329  0.056870       the     1  320  0.0\n",
       "24229       this   7512  0.005007       thi     1  320  0.0\n",
       "24470         to  45176  0.030109        to     1  320  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[TFIDF.sum() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iw1Rbl7FNMwX"
   },
   "source": [
    "### Add stats to Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6EXs82eK4Oj"
   },
   "outputs": [],
   "source": [
    "vocab['tfidf_sum'] = TFIDF.sum()\n",
    "vocab['tfidf_mean'] = TFIDF.mean()\n",
    "vocab['tfidf_max'] = TFIDF.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6EXs82eK4Oj",
    "toc-hr-collapsed": false
   },
   "source": [
    "### Get Top words and Trim Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6EXs82eK4Oj"
   },
   "source": [
    "Basically, implement this SQL query in Pandas:\n",
    "```\n",
    "SELECT * \n",
    "FROM vocab \n",
    "WHERE stop = 0\n",
    "ORDER BY n DESC\n",
    "LIMIT 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6EXs82eK4Oj"
   },
   "outputs": [],
   "source": [
    "def get_top_terms(vocab, no_stops=True, sort_col='n', k=1000):\n",
    "    if no_stops:\n",
    "        V = vocab[vocab.stop == 0]\n",
    "    else:\n",
    "        V = vocab\n",
    "    return V.sort_values(sort_col, ascending=False).head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6EXs82eK4Oj"
   },
   "outputs": [],
   "source": [
    "top_n = 1000\n",
    "TOPV1 = get_top_terms(vocab, sort_col='n')\n",
    "# TOPV2 = get_top_terms(vocab, sort_col='tfidf_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Reduced TFIDF matrix for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_small = TFIDF[TOPV1.index].stack().to_frame().rename(columns={0:'w'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CCiKRQP4gWM",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVQ1HNSn7P5J"
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_name) as db:\n",
    "    vocab.to_sql('vocab', db, if_exists='replace', index=True)\n",
    "    tokens.to_sql('token', db, if_exists='replace', index=True)\n",
    "    docs.to_sql('doc', db, if_exists='replace', index=True)\n",
    "    tfidf_small.to_sql('tfidf_small', db, if_exists='replace', index=True)\n",
    "    bags.reset_index().to_sql('bag', db, if_exists='replace', index=True, index_label='bag_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3BY34SP68yR"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TextmanVectorSpaceMaker.ipynb",
   "provenance": [
    {
     "file_id": "1UJXtZFtWykmkbZSLyLxpKmwiGhXr1w6P",
     "timestamp": 1550268040004
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
