{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "We attempt a Naive Bayes classifier for the sentiment of a corpus of wine reviews. We use the score of the review as our sentiment value, assuming that a bad review will have negative sentiment and a good review will have positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/rca2t/COURSES/DSI/DS5559/UVA_DSI_REPO'\n",
    "local_lib = base_path + '/lib'\n",
    "src_file = 'winereviews.csv'\n",
    "\n",
    "# Set Hyperparameters\n",
    "params = dict(\n",
    "    qntile_B=.1,\n",
    "    qntile_A=.9,\n",
    "    n_sets=4,\n",
    "    smooth_alpha=1,\n",
    "    binary_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "import sys; sys.path.append(local_lib)\n",
    "import textman.textman as tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    docs = pd.read_csv('winereviews.csv', index_col='doc_id')\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_content</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              doc_content  points\n",
       "doc_id                                                           \n",
       "0       Aromas include tropical fruit, broom, brimston...      87\n",
       "1       This is ripe and fruity, a wine that is smooth...      87\n",
       "2       Tart and snappy, the flavors of lime flesh and...      87\n",
       "3       Pineapple rind, lemon pith and orange blossom ...      87\n",
       "4       Much like the regular bottling from 2012, this...      87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip DOC table by quantile\n",
    "\n",
    "We only want reviews that are very good or very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_A = int(docs.points.quantile(params['qntile_A']))\n",
    "bound_B = int(docs.points.quantile(params['qntile_B']))\n",
    "docs = docs[(docs.points <= bound_B) | (docs.points >= bound_A)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 93 \n",
      "B: 84\n"
     ]
    }
   ],
   "source": [
    "print('A:', bound_A, '\\nB:', bound_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DOC points feature to A and B labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.loc[docs.points >= bound_A, 'doc_label'] = 'A'\n",
    "docs.loc[docs.points <= bound_B, 'doc_label'] = 'B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out training and test sets from DOC \n",
    "\n",
    "We randomly assign each doc a value from 0 to 9, and then select one group for testing, i.e. 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['set'] = randint(0,params['n_sets'], len(docs.index))\n",
    "training = docs.query('set != 0').copy()\n",
    "testing = docs.query('set == 0').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get TOKEN and VOCAB from training corpus\n",
    "\n",
    "We use our text parsing library tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, _ = tx.create_tokens_and_vocab(training, src_col='doc_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">336</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Gritty</td>\n",
       "      <td>gritty</td>\n",
       "      <td>6387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavily</td>\n",
       "      <td>heavily</td>\n",
       "      <td>6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roasted</td>\n",
       "      <td>roasted</td>\n",
       "      <td>11688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aromas</td>\n",
       "      <td>aromas</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peanuts</td>\n",
       "      <td>peanuts</td>\n",
       "      <td>10071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           token term_str  term_id\n",
       "doc_id sent_id token_id                           \n",
       "336    0       0          Gritty   gritty     6387\n",
       "               1         heavily  heavily     6645\n",
       "               2         roasted  roasted    11688\n",
       "               3          aromas   aromas      968\n",
       "               5         peanuts  peanuts    10071"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add sentiment label to TOKEN\n",
    "\n",
    "We now transfer the doc label to the tokens, by transitive inheritance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.join(training.doc_label, on='doc_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VOCAB from TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokens.groupby('term_id').term_str.value_counts()\\\n",
    "    .to_frame().rename(columns={'term_str':'n'})\n",
    "vocab = vocab.reset_index().set_index('term_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>aaron</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>abandon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>abbey</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>ability</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>able</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>abound</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>abounds</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>abrasive</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>abrie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>abrupt</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>abruptly</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>abruzzo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>absence</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>absolute</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>abundance</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>abundant</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>abv</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>acacia</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>accent</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>accented</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>accenting</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>accents</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>accentuate</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>accentuated</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>accentuates</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>acceptability</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>acceptable</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>access</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>accessibility</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15716</th>\n",
       "      <td>young</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15717</th>\n",
       "      <td>younger</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15720</th>\n",
       "      <td>yountville</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15723</th>\n",
       "      <td>youth</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15724</th>\n",
       "      <td>youthful</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>youthfully</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15726</th>\n",
       "      <td>youthfulness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15727</th>\n",
       "      <td>yum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>yummy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>yuzu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>zaca</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>zealand</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15739</th>\n",
       "      <td>zeller</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>zero</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>zest</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15747</th>\n",
       "      <td>zestiness</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15748</th>\n",
       "      <td>zesty</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15749</th>\n",
       "      <td>zibibbo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15750</th>\n",
       "      <td>zin</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15752</th>\n",
       "      <td>zinfandel</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15753</th>\n",
       "      <td>zinfandels</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15754</th>\n",
       "      <td>zing</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>zingy</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15758</th>\n",
       "      <td>zinny</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15759</th>\n",
       "      <td>zins</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15760</th>\n",
       "      <td>zip</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15762</th>\n",
       "      <td>zippy</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15766</th>\n",
       "      <td>zone</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15771</th>\n",
       "      <td>zweigelt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>über</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              term_str    n\n",
       "term_id                    \n",
       "337              aaron    3\n",
       "339            abandon    3\n",
       "340              abbey    3\n",
       "349            ability   26\n",
       "350               able   12\n",
       "354             abound   25\n",
       "355            abounds    9\n",
       "359           abrasive   31\n",
       "361              abrie    3\n",
       "362             abrupt   11\n",
       "363           abruptly    7\n",
       "364            abruzzo    3\n",
       "366            absence    9\n",
       "369           absolute   19\n",
       "370         absolutely   78\n",
       "373          abundance   20\n",
       "374           abundant   30\n",
       "379                abv   15\n",
       "380             acacia   32\n",
       "382             accent  101\n",
       "383           accented  176\n",
       "384          accenting   12\n",
       "385            accents  171\n",
       "386         accentuate    4\n",
       "387        accentuated    6\n",
       "388        accentuates   14\n",
       "390      acceptability    3\n",
       "391         acceptable   37\n",
       "392             access    3\n",
       "393      accessibility    4\n",
       "...                ...  ...\n",
       "15716            young  636\n",
       "15717          younger    7\n",
       "15720       yountville    6\n",
       "15723            youth   55\n",
       "15724         youthful  115\n",
       "15725       youthfully   65\n",
       "15726     youthfulness    5\n",
       "15727              yum    4\n",
       "15728            yummy    5\n",
       "15729             yuzu    4\n",
       "15733             zaca    6\n",
       "15738          zealand    8\n",
       "15739           zeller    5\n",
       "15743             zero   12\n",
       "15744             zest  375\n",
       "15747        zestiness   34\n",
       "15748            zesty  275\n",
       "15749          zibibbo    3\n",
       "15750              zin  129\n",
       "15752        zinfandel  146\n",
       "15753       zinfandels    4\n",
       "15754             zing   13\n",
       "15757            zingy   16\n",
       "15758            zinny    4\n",
       "15759             zins    9\n",
       "15760              zip   10\n",
       "15762            zippy   28\n",
       "15766             zone    5\n",
       "15771         zweigelt    7\n",
       "15778             über    6\n",
       "\n",
       "[7266 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.reset_index()[['doc_label', 'doc_id', 'term_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_label</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375018</th>\n",
       "      <td>A</td>\n",
       "      <td>109056</td>\n",
       "      <td>12823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230319</th>\n",
       "      <td>A</td>\n",
       "      <td>65619</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345537</th>\n",
       "      <td>A</td>\n",
       "      <td>100252</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377197</th>\n",
       "      <td>A</td>\n",
       "      <td>109438</td>\n",
       "      <td>12697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225056</th>\n",
       "      <td>A</td>\n",
       "      <td>63629</td>\n",
       "      <td>9482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_label  doc_id  term_id\n",
       "375018         A  109056    12823\n",
       "230319         A   65619    11919\n",
       "345537         A  100252      672\n",
       "377197         A  109438    12697\n",
       "225056         A   63629     9482"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Priors\n",
    "\n",
    "We compute the probability of each label in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = tokens.groupby('doc_label').doc_id.count()\n",
    "priors = priors / priors.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Likelihoods\n",
    "\n",
    "Now we compute the probability of a token given the label. This will in effect product two language models, one for each label. Key idea = **the likelihoods are language models** (see Pearl for interpretation of likelihoods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = tokens.groupby(['doc_label'])\\\n",
    "    .term_id.value_counts()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})\\\n",
    "    .reset_index()\n",
    "likelihoods = likelihoods.set_index(['term_id','doc_label']).n.unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = (likelihoods + params['smooth_alpha'])\\\n",
    "    .div(likelihoods.sum() + (len(vocab.index) * params['smooth_alpha']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test corpus\n",
    "\n",
    "Note that we replace the vocabulary IDs with the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, _ = tx.create_tokens_and_vocab(testing, src_col='doc_content')\n",
    "test['term_id'] = test.term_str.map(vocab.reset_index().set_index('term_str').term_id)\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Convert corpus to BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = test.groupby(['doc_id','term_id']).term_id.count()\\\n",
    "    .unstack().apply(lambda x: x.dropna().index.astype('int').tolist(), 1)\\\n",
    "    .to_frame().rename(columns={0:'bow'})\n",
    "test_docs['doc_label'] = testing.doc_label\n",
    "if params['binary_counts']:\n",
    "    # set() forces BOW to consist of only one token for each term\n",
    "    test_docs['bow'] = test_docs.bow.apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Compute POSTERIOR and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = test_docs.bow.apply(lambda x: likelihoods.loc[x].product() * priors)\n",
    "test_docs['prediction'] = posteriors.T.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs['result'] = test_docs.doc_label == test_docs.prediction\n",
    "T, F = test_docs.result.value_counts()\n",
    "grade = round(T/(T+F) * 100, 4)\n",
    "CM = test_docs.reset_index().groupby(['doc_label','prediction']).doc_id.count().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "      RESULTS\n",
      "----------------------\n",
      "Grade: 96.1513\n",
      "----------------------\n",
      "Confusion matrix:\n",
      "prediction     A     B\n",
      "doc_label             \n",
      "A           2993    43\n",
      "B            187  2753\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "print(\"______________________\")\n",
    "print(\"      RESULTS\")\n",
    "print(\"----------------------\")\n",
    "print('Grade:', grade)\n",
    "print(\"----------------------\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(CM)\n",
    "print(\"______________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
